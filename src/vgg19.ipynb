{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.12.0\n",
      "2.1.6-tf\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tensorflow import keras\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "print(tf.__version__)\n",
    "print(keras.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.test.is_gpu_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found GPU at: /device:GPU:0\n"
     ]
    }
   ],
   "source": [
    "device_name = tf.test.gpu_device_name()\n",
    "if device_name != '/device:GPU:0':\n",
    "  raise SystemError('GPU device not found')\n",
    "print('Found GPU at: {}'.format(device_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.keras.applications.resnet50 as resnet50 \n",
    "import tensorflow.keras.applications.vgg19 as vgg19\n",
    "# import tensorflow.keras.applications.vgg19 as vgg19\n",
    "import tensorflow.keras.applications.densenet as densenet\n",
    "import tensorflow.keras.applications.inception_v3 as inception_v3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.keras.applications.vgg19 as vgg19"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.keras.preprocessing.image as image\n",
    "import tensorflow.keras.losses as losses\n",
    "import tensorflow.keras.layers as layers\n",
    "import tensorflow.keras.models as models\n",
    "import tensorflow.keras.callbacks as callbacks\n",
    "import tensorflow.keras.backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.io import loadmat\n",
    "from os.path import join\n",
    "\n",
    "prefix = './Stanford_Dog_Breed'\n",
    "imgfix = 'Images'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 12000 images belonging to 120 classes.\n",
      "Found 8580 images belonging to 120 classes.\n"
     ]
    }
   ],
   "source": [
    "ImgTrainGen = image.ImageDataGenerator(preprocessing_function=vgg19.preprocess_input, \n",
    "                                  width_shift_range=0.2, \n",
    "                                  height_shift_range=0.2, \n",
    "                                  shear_range=0.2, \n",
    "                                  zoom_range=0.2,\n",
    "                                  rotation_range=0.2,\n",
    "                                  fill_mode='nearest',\n",
    "                                  horizontal_flip=True, \n",
    "                                  vertical_flip=True, \n",
    "#                                   validation_split=1/6.\n",
    "                                      )\n",
    "\n",
    "Train = ImgTrainGen.flow_from_directory(join(prefix, imgfix, 'Train'), \n",
    "                                   target_size=(224, 224), \n",
    "                                   class_mode='sparse', \n",
    "                                   batch_size=32, \n",
    "                                   shuffle=True, \n",
    "                                   seed=None, \n",
    "                                   subset='training', \n",
    "                                   interpolation='nearest')\n",
    "\n",
    "ImgTestGen = image.ImageDataGenerator(preprocessing_function=vgg19.preprocess_input, validation_split=1/6.)\n",
    "\n",
    "Test  = ImgTestGen.flow_from_directory(join(prefix, imgfix, 'Test' ), \n",
    "                                       target_size=(224, 224), \n",
    "                                       class_mode='sparse', \n",
    "                                       batch_size=32, \n",
    "                                       shuffle=False, \n",
    "                                       interpolation='nearest')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MultiTaskDataGen(ImgGen):\n",
    "    while True:\n",
    "        X = ImgGen.next()\n",
    "        yield [X[0], X[1]], [X[1], X[1], X[1]]\n",
    "        \n",
    "TrainData = MultiTaskDataGen(Train)\n",
    "# ValidData = MultiTaskDataGen(Valid)\n",
    "TestData  = MultiTaskDataGen(Test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VGG 19"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "vgg19_naive = vgg19.VGG19(weights='imagenet', include_top=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         (None, 224, 224, 3)       0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 224, 224, 64)      1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 224, 224, 64)      36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 112, 112, 64)      0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 112, 112, 128)     73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 112, 112, 128)     147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 56, 56, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 56, 56, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv4 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 28, 28, 256)       0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 28, 28, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv4 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv4 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 7, 7, 512)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 25088)             0         \n",
      "_________________________________________________________________\n",
      "fc1 (Dense)                  (None, 4096)              102764544 \n",
      "_________________________________________________________________\n",
      "fc2 (Dense)                  (None, 4096)              16781312  \n",
      "_________________________________________________________________\n",
      "predictions (Dense)          (None, 1000)              4097000   \n",
      "=================================================================\n",
      "Total params: 143,667,240\n",
      "Trainable params: 143,667,240\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "vgg19_naive.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_image = vgg19_naive.input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(?, 4096)\n",
      "(?, 120)\n"
     ]
    }
   ],
   "source": [
    "# from tensorflow.keras.layers import Flatten,Dropout,Dense\n",
    "# from tensorflow.keras.models import Sequential\n",
    "# from tensorflow.keras.layers import Flatten, Dense, Dropout\n",
    "\n",
    "# from tensorflow.keras.optimizers import SGD\n",
    "\n",
    "x = vgg19_naive.get_layer('fc2').output\n",
    "print(x.shape)\n",
    "# vgg19_naive.add(Flatten())\n",
    "# vgg19_naive.add(Dense(4096, activation='relu'))\n",
    "# vgg19_naive.add(Dropout(0.5))\n",
    "# vgg19_naive.add(Dense(4096, activation='relu'))\n",
    "# vgg19_naive.add(Dropout(0.5))\n",
    "# vgg19_naive.add(Dense(1000, activation='softmax'))\n",
    "\n",
    "# x = layers.Conv1D(filters=None, kernel_size=1, activation='relu')(x)\n",
    "# x = Flatten()(x)\n",
    "# x = layers.Dense(4096, activation='relu')(x)\n",
    "# x = layers.Conv1D(filters=4096, kernel_size=1, activation='relu')(x)\n",
    "# print(x.shape)\n",
    "# x = layers.MaxPooling2D(pool_size=(2, 2))(x)\n",
    "# # x = Flatten()(x)\n",
    "# x = Dense(256, activation='relu')(x)\n",
    "x = layers.Dropout(0.5)(x)\n",
    "x = layers.Dense(120, activation='softmax')(x)\n",
    "print(x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         (None, 224, 224, 3)       0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 224, 224, 64)      1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 224, 224, 64)      36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 112, 112, 64)      0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 112, 112, 128)     73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 112, 112, 128)     147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 56, 56, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 56, 56, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv4 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 28, 28, 256)       0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 28, 28, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv4 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv4 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 7, 7, 512)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 25088)             0         \n",
      "_________________________________________________________________\n",
      "fc1 (Dense)                  (None, 4096)              102764544 \n",
      "_________________________________________________________________\n",
      "fc2 (Dense)                  (None, 4096)              16781312  \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 120)               491640    \n",
      "=================================================================\n",
      "Total params: 140,061,880\n",
      "Trainable params: 491,640\n",
      "Non-trainable params: 139,570,240\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = models.Model(inputs=input_image, outputs=x)\n",
    "for layer in vgg19_naive.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "model.compile(\n",
    "    optimizer='SGD', \n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    metrics=['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Callbacks\n",
    "class SaveModelandEval(callbacks.Callback):\n",
    "    prev_res = list()\n",
    "    def __init__(self):\n",
    "        self.prev_res = [0., 0.]\n",
    "    def on_epoch_end(self, epoch, logs):\n",
    "        if epoch == 0: return\n",
    "        if epoch % 5 == 0:\n",
    "            res = model.evaluate_generator(Test, verbose=0, steps=None, workers=4, use_multiprocessing=True, max_queue_size=12)\n",
    "            print('\\n', res)\n",
    "            if res[1] > self.prev_res[1]:\n",
    "                models.save_model(model, 'vgg19_dfc120_%s_%s'%(epoch, int(res[1]*10000)) )\n",
    "                self.prev_res = res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         (None, None, None, 3)     0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, None, None, 64)    1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, None, None, 64)    36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, None, None, 64)    0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, None, None, 128)   73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, None, None, 128)   147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, None, None, 128)   0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, None, None, 256)   295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, None, None, 256)   590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, None, None, 256)   590080    \n",
      "_________________________________________________________________\n",
      "block3_conv4 (Conv2D)        (None, None, None, 256)   590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, None, None, 256)   0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, None, None, 512)   1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, None, None, 512)   2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, None, None, 512)   2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv4 (Conv2D)        (None, None, None, 512)   2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, None, None, 512)   0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, None, None, 512)   2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, None, None, 512)   2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, None, None, 512)   2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv4 (Conv2D)        (None, None, None, 512)   2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, None, None, 512)   0         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, None, None, 4096)  2101248   \n",
      "_________________________________________________________________\n",
      "max_pooling2d_14 (MaxPooling (None, None, None, 4096)  0         \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, None, None, 4096)  0         \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, None, None, 120)   491640    \n",
      "=================================================================\n",
      "Total params: 22,617,272\n",
      "Trainable params: 2,592,888\n",
      "Non-trainable params: 20,024,384\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras.optimizers import SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.load_model('vgg19_dfc120_40_6751')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/101\n",
      "80/80 [==============================] - 21s 257ms/step - loss: 2.8131 - acc: 0.4223\n",
      "Epoch 2/101\n",
      "80/80 [==============================] - 20s 251ms/step - loss: 2.8256 - acc: 0.4023\n",
      "Epoch 3/101\n",
      "80/80 [==============================] - 20s 252ms/step - loss: 2.7468 - acc: 0.4164\n",
      "Epoch 4/101\n",
      "80/80 [==============================] - 20s 251ms/step - loss: 2.6021 - acc: 0.4410\n",
      "Epoch 5/101\n",
      "80/80 [==============================] - 21s 260ms/step - loss: 2.7336 - acc: 0.4129\n",
      "Epoch 6/101\n",
      "79/80 [============================>.] - ETA: 0s - loss: 2.4894 - acc: 0.4498\n",
      " [1.1161121639302145, 0.7044289044289044]\n",
      "80/80 [==============================] - 89s 1s/step - loss: 2.4884 - acc: 0.4488\n",
      "Epoch 7/101\n",
      "80/80 [==============================] - 20s 252ms/step - loss: 2.4072 - acc: 0.4570\n",
      "Epoch 8/101\n",
      "80/80 [==============================] - 20s 252ms/step - loss: 2.4449 - acc: 0.4520\n",
      "Epoch 9/101\n",
      "80/80 [==============================] - 20s 253ms/step - loss: 2.5053 - acc: 0.4438\n",
      "Epoch 10/101\n",
      "80/80 [==============================] - 21s 259ms/step - loss: 2.3564 - acc: 0.4562\n",
      "Epoch 11/101\n",
      "79/80 [============================>.] - ETA: 0s - loss: 2.4056 - acc: 0.4557\n",
      " [1.0673878484086488, 0.7186480186480186]\n",
      "80/80 [==============================] - 89s 1s/step - loss: 2.4036 - acc: 0.4559\n",
      "Epoch 12/101\n",
      "80/80 [==============================] - 20s 252ms/step - loss: 2.4019 - acc: 0.4477\n",
      "Epoch 13/101\n",
      "80/80 [==============================] - 20s 253ms/step - loss: 2.2708 - acc: 0.4711\n",
      "Epoch 14/101\n",
      "80/80 [==============================] - 20s 253ms/step - loss: 2.4104 - acc: 0.4617\n",
      "Epoch 15/101\n",
      "80/80 [==============================] - 21s 259ms/step - loss: 2.1198 - acc: 0.4918\n",
      "Epoch 16/101\n",
      "79/80 [============================>.] - ETA: 0s - loss: 2.2187 - acc: 0.4814\n",
      " [1.0744385927653164, 0.7243589743589743]\n",
      "80/80 [==============================] - 89s 1s/step - loss: 2.2094 - acc: 0.4832\n",
      "Epoch 17/101\n",
      "80/80 [==============================] - 20s 252ms/step - loss: 2.1987 - acc: 0.4836\n",
      "Epoch 18/101\n",
      "80/80 [==============================] - 20s 252ms/step - loss: 2.2678 - acc: 0.4789\n",
      "Epoch 19/101\n",
      "80/80 [==============================] - 21s 259ms/step - loss: 2.1757 - acc: 0.4789\n",
      "Epoch 20/101\n",
      "80/80 [==============================] - 20s 253ms/step - loss: 2.0970 - acc: 0.5051\n",
      "Epoch 21/101\n",
      "79/80 [============================>.] - ETA: 0s - loss: 2.1376 - acc: 0.4893\n",
      " [1.0709060405258979, 0.7228438228438229]\n",
      "80/80 [==============================] - 88s 1s/step - loss: 2.1396 - acc: 0.4891\n",
      "Epoch 22/101\n",
      "80/80 [==============================] - 20s 252ms/step - loss: 2.1266 - acc: 0.4977\n",
      "Epoch 23/101\n",
      "80/80 [==============================] - 20s 253ms/step - loss: 2.1569 - acc: 0.4988\n",
      "Epoch 24/101\n",
      "80/80 [==============================] - 21s 260ms/step - loss: 2.1763 - acc: 0.4902\n",
      "Epoch 25/101\n",
      "80/80 [==============================] - 20s 252ms/step - loss: 1.9700 - acc: 0.5328\n",
      "Epoch 26/101\n",
      "79/80 [============================>.] - ETA: 0s - loss: 1.9499 - acc: 0.5305\n",
      " [1.0785954542819447, 0.7236596736596737]\n",
      "80/80 [==============================] - 88s 1s/step - loss: 1.9523 - acc: 0.5316\n",
      "Epoch 27/101\n",
      "80/80 [==============================] - 20s 253ms/step - loss: 2.0063 - acc: 0.5180\n",
      "Epoch 28/101\n",
      "80/80 [==============================] - 20s 253ms/step - loss: 2.0136 - acc: 0.5184\n",
      "Epoch 29/101\n",
      "80/80 [==============================] - 21s 259ms/step - loss: 2.0043 - acc: 0.5043\n",
      "Epoch 30/101\n",
      "80/80 [==============================] - 20s 252ms/step - loss: 1.9614 - acc: 0.5277\n",
      "Epoch 31/101\n",
      "79/80 [============================>.] - ETA: 0s - loss: 1.9819 - acc: 0.5134\n",
      " [1.0197694172711331, 0.7376456876456876]\n",
      "80/80 [==============================] - 89s 1s/step - loss: 1.9812 - acc: 0.5145\n",
      "Epoch 32/101\n",
      "80/80 [==============================] - 20s 252ms/step - loss: 2.0318 - acc: 0.5184\n",
      "Epoch 33/101\n",
      "80/80 [==============================] - 21s 259ms/step - loss: 2.1331 - acc: 0.4891\n",
      "Epoch 34/101\n",
      "80/80 [==============================] - 20s 252ms/step - loss: 1.9306 - acc: 0.5234\n",
      "Epoch 35/101\n",
      "80/80 [==============================] - 20s 252ms/step - loss: 1.9565 - acc: 0.5172\n",
      "Epoch 36/101\n",
      "79/80 [============================>.] - ETA: 0s - loss: 1.9967 - acc: 0.5103\n",
      " [1.0487454773289444, 0.7314685314685314]\n",
      "80/80 [==============================] - 88s 1s/step - loss: 1.9969 - acc: 0.5094\n",
      "Epoch 37/101\n",
      "80/80 [==============================] - 20s 252ms/step - loss: 2.1479 - acc: 0.4945\n",
      "Epoch 38/101\n",
      "80/80 [==============================] - 21s 260ms/step - loss: 1.9152 - acc: 0.5332\n",
      "Epoch 39/101\n",
      "80/80 [==============================] - 20s 252ms/step - loss: 1.8521 - acc: 0.5441\n",
      "Epoch 40/101\n",
      "80/80 [==============================] - 20s 252ms/step - loss: 1.8541 - acc: 0.5500\n",
      "Epoch 41/101\n",
      "79/80 [============================>.] - ETA: 0s - loss: 2.0106 - acc: 0.5186\n",
      " [1.060308739268013, 0.7235431235431236]\n",
      "80/80 [==============================] - 88s 1s/step - loss: 2.0099 - acc: 0.5180\n",
      "Epoch 42/101\n",
      "80/80 [==============================] - 20s 252ms/step - loss: 2.0078 - acc: 0.5145\n",
      "Epoch 43/101\n",
      "80/80 [==============================] - 21s 259ms/step - loss: 1.9565 - acc: 0.5250\n",
      "Epoch 44/101\n",
      "80/80 [==============================] - 20s 252ms/step - loss: 1.8897 - acc: 0.5355\n",
      "Epoch 45/101\n",
      "80/80 [==============================] - 20s 252ms/step - loss: 1.8729 - acc: 0.5383\n",
      "Epoch 46/101\n",
      "79/80 [============================>.] - ETA: 0s - loss: 1.8817 - acc: 0.5419\n",
      " [1.0675707786091013, 0.7321678321678322]\n",
      "80/80 [==============================] - 88s 1s/step - loss: 1.8835 - acc: 0.5414\n",
      "Epoch 47/101\n",
      "80/80 [==============================] - 21s 259ms/step - loss: 1.8076 - acc: 0.5379\n",
      "Epoch 48/101\n",
      "80/80 [==============================] - 20s 252ms/step - loss: 1.8154 - acc: 0.5445\n",
      "Epoch 49/101\n",
      "80/80 [==============================] - 20s 252ms/step - loss: 1.8292 - acc: 0.5453\n",
      "Epoch 50/101\n",
      "80/80 [==============================] - 20s 252ms/step - loss: 1.8858 - acc: 0.5258\n",
      "Epoch 51/101\n",
      "79/80 [============================>.] - ETA: 0s - loss: 1.8268 - acc: 0.5526\n",
      " [1.0301533856837564, 0.7361305361305361]\n",
      "80/80 [==============================] - 88s 1s/step - loss: 1.8249 - acc: 0.5527\n",
      "Epoch 52/101\n",
      "80/80 [==============================] - 21s 259ms/step - loss: 1.9223 - acc: 0.5324\n",
      "Epoch 53/101\n",
      "80/80 [==============================] - 20s 253ms/step - loss: 1.7373 - acc: 0.5605\n",
      "Epoch 54/101\n",
      "80/80 [==============================] - 20s 252ms/step - loss: 1.8145 - acc: 0.5504\n",
      "Epoch 55/101\n",
      "80/80 [==============================] - 20s 253ms/step - loss: 1.7849 - acc: 0.5527\n",
      "Epoch 56/101\n",
      "79/80 [============================>.] - ETA: 0s - loss: 1.8933 - acc: 0.5336\n",
      " [1.0980507119372018, 0.7277389277389278]\n",
      "80/80 [==============================] - 88s 1s/step - loss: 1.8965 - acc: 0.5328\n",
      "Epoch 57/101\n",
      "80/80 [==============================] - 21s 259ms/step - loss: 1.6640 - acc: 0.5766\n",
      "Epoch 58/101\n",
      "80/80 [==============================] - 20s 252ms/step - loss: 1.6893 - acc: 0.5719\n",
      "Epoch 59/101\n",
      "80/80 [==============================] - 20s 252ms/step - loss: 1.7821 - acc: 0.5434\n",
      "Epoch 60/101\n",
      "80/80 [==============================] - 20s 252ms/step - loss: 1.7880 - acc: 0.5559\n",
      "Epoch 61/101\n",
      "79/80 [============================>.] - ETA: 0s - loss: 1.9705 - acc: 0.5281\n",
      " [1.068617146398752, 0.7224941724941725]\n",
      "80/80 [==============================] - 89s 1s/step - loss: 1.9711 - acc: 0.5285\n",
      "Epoch 62/101\n",
      "80/80 [==============================] - 20s 253ms/step - loss: 1.6674 - acc: 0.5812\n",
      "Epoch 63/101\n",
      "80/80 [==============================] - 20s 252ms/step - loss: 1.7616 - acc: 0.5582\n",
      "Epoch 64/101\n",
      "80/80 [==============================] - 20s 252ms/step - loss: 1.7452 - acc: 0.5578\n",
      "Epoch 65/101\n",
      "80/80 [==============================] - 20s 252ms/step - loss: 1.7626 - acc: 0.5473\n",
      "Epoch 66/101\n",
      "79/80 [============================>.] - ETA: 0s - loss: 1.7559 - acc: 0.5530\n",
      " [1.0894574115146949, 0.7347319347319348]\n",
      "80/80 [==============================] - 89s 1s/step - loss: 1.7679 - acc: 0.5520\n",
      "Epoch 67/101\n",
      "80/80 [==============================] - 20s 253ms/step - loss: 1.6694 - acc: 0.5691\n",
      "Epoch 68/101\n",
      "80/80 [==============================] - 20s 253ms/step - loss: 1.7629 - acc: 0.5613\n",
      "Epoch 69/101\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80/80 [==============================] - 20s 252ms/step - loss: 1.8140 - acc: 0.5504\n",
      "Epoch 70/101\n",
      "80/80 [==============================] - 20s 252ms/step - loss: 1.7471 - acc: 0.5613\n",
      "Epoch 71/101\n",
      "79/80 [============================>.] - ETA: 0s - loss: 1.7379 - acc: 0.5617\n",
      " [1.0685623348592386, 0.732983682983683]\n",
      "80/80 [==============================] - 89s 1s/step - loss: 1.7331 - acc: 0.5637\n",
      "Epoch 72/101\n",
      "80/80 [==============================] - 20s 252ms/step - loss: 1.6774 - acc: 0.5660\n",
      "Epoch 73/101\n",
      "80/80 [==============================] - 20s 252ms/step - loss: 1.7117 - acc: 0.5629\n",
      "Epoch 74/101\n",
      "80/80 [==============================] - 20s 252ms/step - loss: 1.7459 - acc: 0.5473\n",
      "Epoch 75/101\n",
      "80/80 [==============================] - 20s 253ms/step - loss: 1.6980 - acc: 0.5766\n",
      "Epoch 76/101\n",
      "79/80 [============================>.] - ETA: 0s - loss: 1.6002 - acc: 0.5791\n",
      " [1.028884679842485, 0.7353146853146854]\n",
      "80/80 [==============================] - 89s 1s/step - loss: 1.5985 - acc: 0.5793\n",
      "Epoch 77/101\n",
      "80/80 [==============================] - 20s 252ms/step - loss: 1.6337 - acc: 0.5793\n",
      "Epoch 78/101\n",
      "80/80 [==============================] - 20s 253ms/step - loss: 1.6243 - acc: 0.5777\n",
      "Epoch 79/101\n",
      "80/80 [==============================] - 20s 253ms/step - loss: 1.6863 - acc: 0.5797\n",
      "Epoch 80/101\n",
      "80/80 [==============================] - 21s 260ms/step - loss: 1.6611 - acc: 0.5855\n",
      "Epoch 81/101\n",
      "79/80 [============================>.] - ETA: 0s - loss: 1.6357 - acc: 0.5815\n",
      " [1.0815086227955784, 0.7258741258741259]\n",
      "80/80 [==============================] - 88s 1s/step - loss: 1.6389 - acc: 0.5805\n",
      "Epoch 82/101\n",
      "80/80 [==============================] - 20s 252ms/step - loss: 1.6157 - acc: 0.5809\n",
      "Epoch 83/101\n",
      "80/80 [==============================] - 20s 253ms/step - loss: 1.6204 - acc: 0.5824\n",
      "Epoch 84/101\n",
      "80/80 [==============================] - 20s 253ms/step - loss: 1.6589 - acc: 0.5793\n",
      "Epoch 85/101\n",
      "80/80 [==============================] - 21s 260ms/step - loss: 1.6350 - acc: 0.5785\n",
      "Epoch 86/101\n",
      "79/80 [============================>.] - ETA: 0s - loss: 1.6431 - acc: 0.5771\n",
      " [1.0607219521478146, 0.7290209790209791]\n",
      "80/80 [==============================] - 88s 1s/step - loss: 1.6491 - acc: 0.5758\n",
      "Epoch 87/101\n",
      "80/80 [==============================] - 20s 252ms/step - loss: 1.6414 - acc: 0.5738\n",
      "Epoch 88/101\n",
      "80/80 [==============================] - 20s 253ms/step - loss: 1.5915 - acc: 0.5848\n",
      "Epoch 89/101\n",
      "80/80 [==============================] - 20s 254ms/step - loss: 1.7046 - acc: 0.5723\n",
      "Epoch 90/101\n",
      "80/80 [==============================] - 21s 259ms/step - loss: 1.5149 - acc: 0.6008\n",
      "Epoch 91/101\n",
      "79/80 [============================>.] - ETA: 0s - loss: 1.5782 - acc: 0.5953\n",
      " [1.0571545743682478, 0.734965034965035]\n",
      "80/80 [==============================] - 88s 1s/step - loss: 1.5791 - acc: 0.5949\n",
      "Epoch 92/101\n",
      "80/80 [==============================] - 20s 252ms/step - loss: 1.6346 - acc: 0.5836\n",
      "Epoch 93/101\n",
      "80/80 [==============================] - 20s 252ms/step - loss: 1.6328 - acc: 0.5766\n",
      "Epoch 94/101\n",
      "80/80 [==============================] - 21s 260ms/step - loss: 1.6468 - acc: 0.5754\n",
      "Epoch 95/101\n",
      "80/80 [==============================] - 20s 253ms/step - loss: 1.5277 - acc: 0.6004\n",
      "Epoch 96/101\n",
      "79/80 [============================>.] - ETA: 0s - loss: 1.5963 - acc: 0.5918\n",
      " [1.0596899267730997, 0.7336829836829837]\n",
      "80/80 [==============================] - 88s 1s/step - loss: 1.6086 - acc: 0.5898\n",
      "Epoch 97/101\n",
      "80/80 [==============================] - 20s 252ms/step - loss: 1.6319 - acc: 0.5781\n",
      "Epoch 98/101\n",
      "80/80 [==============================] - 20s 252ms/step - loss: 1.6078 - acc: 0.5844\n",
      "Epoch 99/101\n",
      "80/80 [==============================] - 21s 259ms/step - loss: 1.6097 - acc: 0.5754\n",
      "Epoch 100/101\n",
      "80/80 [==============================] - 20s 252ms/step - loss: 1.5730 - acc: 0.5918\n",
      "Epoch 101/101\n",
      "79/80 [============================>.] - ETA: 0s - loss: 1.5926 - acc: 0.5965\n",
      " [1.0560044984020274, 0.7363636363636363]\n",
      "80/80 [==============================] - 88s 1s/step - loss: 1.5888 - acc: 0.5969\n"
     ]
    }
   ],
   "source": [
    "history_vgg19=model.fit_generator(\n",
    "    Train, \n",
    "    steps_per_epoch=80, \n",
    "    epochs=101, \n",
    "    verbose=1, \n",
    "    workers=4,\n",
    "    use_multiprocessing=True,\n",
    "    max_queue_size=20,\n",
    "    initial_epoch=0,\n",
    "#     validation_data=Test,\n",
    "#     validation_steps=20,\n",
    "    callbacks=[SaveModelandEval()]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open('history_vgg19.json', 'w') as f:\n",
    "    json.dump(history_vgg19.history, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fine Tune"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.load_model('vgg19_dfc120_30_7376')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, u'input_1')\n",
      "(1, u'block1_conv1')\n",
      "(2, u'block1_conv2')\n",
      "(3, u'block1_pool')\n",
      "(4, u'block2_conv1')\n",
      "(5, u'block2_conv2')\n",
      "(6, u'block2_pool')\n",
      "(7, u'block3_conv1')\n",
      "(8, u'block3_conv2')\n",
      "(9, u'block3_conv3')\n",
      "(10, u'block3_conv4')\n",
      "(11, u'block3_pool')\n",
      "(12, u'block4_conv1')\n",
      "(13, u'block4_conv2')\n",
      "(14, u'block4_conv3')\n",
      "(15, u'block4_conv4')\n",
      "(16, u'block4_pool')\n",
      "(17, u'block5_conv1')\n",
      "(18, u'block5_conv2')\n",
      "(19, u'block5_conv3')\n",
      "(20, u'block5_conv4')\n",
      "(21, u'block5_pool')\n",
      "(22, u'global_average_pooling2d')\n",
      "(23, u'dropout')\n",
      "(24, u'dense')\n"
     ]
    }
   ],
   "source": [
    "for i, layer in enumerate(model.layers):\n",
    "    print(i, layer.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in model.layers[:12]:\n",
    "    layer.trainable = False\n",
    "for layer in model.layers[12:]:\n",
    "    layer.trainable = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras.optimizers import SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=SGD(lr=0.0001, momentum=0.9), loss='sparse_categorical_crossentropy',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Callbacks\n",
    "class SaveModelandEval_finetune(callbacks.Callback):\n",
    "    prev_res = list()\n",
    "    def __init__(self):\n",
    "        self.prev_res = [0., 0.]\n",
    "    def on_epoch_end(self, epoch, logs):\n",
    "        if epoch == 0: return\n",
    "        if epoch % 3 == 0:\n",
    "            res = model.evaluate_generator(Test, verbose=0, steps=None, workers=4, use_multiprocessing=True, max_queue_size=12)\n",
    "            print('\\n', res)\n",
    "            if res[1] > self.prev_res[1]:\n",
    "                models.save_model(model, 'vgg19_dfc120_finetune_%s_%s'%(epoch, int(res[1]*10000)) )\n",
    "                self.prev_res = res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/22\n",
      "80/80 [==============================] - 37s 464ms/step - loss: 1.6655 - acc: 0.5527\n",
      "Epoch 2/22\n",
      "80/80 [==============================] - 34s 423ms/step - loss: 1.5787 - acc: 0.5547\n",
      "Epoch 3/22\n",
      "80/80 [==============================] - 34s 423ms/step - loss: 1.5828 - acc: 0.5563\n",
      "Epoch 4/22\n",
      "79/80 [============================>.] - ETA: 0s - loss: 1.4967 - acc: 0.5779\n",
      " [0.898190791537119, 0.7385780885780886]\n",
      "80/80 [==============================] - 103s 1s/step - loss: 1.4912 - acc: 0.5793\n",
      "Epoch 5/22\n",
      "80/80 [==============================] - 34s 430ms/step - loss: 1.4623 - acc: 0.5891\n",
      "Epoch 6/22\n",
      "80/80 [==============================] - 34s 425ms/step - loss: 1.3301 - acc: 0.6180\n",
      "Epoch 7/22\n",
      "79/80 [============================>.] - ETA: 0s - loss: 1.3214 - acc: 0.6104\n",
      " [0.880990124828104, 0.742074592074592]\n",
      "80/80 [==============================] - 103s 1s/step - loss: 1.3305 - acc: 0.6090\n",
      "Epoch 8/22\n",
      "80/80 [==============================] - 34s 425ms/step - loss: 1.3333 - acc: 0.6246\n",
      "Epoch 9/22\n",
      "80/80 [==============================] - 34s 425ms/step - loss: 1.3042 - acc: 0.6238\n",
      "Epoch 10/22\n",
      "79/80 [============================>.] - ETA: 0s - loss: 1.2758 - acc: 0.6305\n",
      " [0.8499027096793937, 0.7482517482517482]\n",
      "80/80 [==============================] - 103s 1s/step - loss: 1.2716 - acc: 0.6320\n",
      "Epoch 11/22\n",
      "80/80 [==============================] - 34s 425ms/step - loss: 1.1834 - acc: 0.6512\n",
      "Epoch 12/22\n",
      "80/80 [==============================] - 34s 425ms/step - loss: 1.2377 - acc: 0.6406\n",
      "Epoch 13/22\n",
      "79/80 [============================>.] - ETA: 0s - loss: 1.2101 - acc: 0.6337\n",
      " [0.9151553788371081, 0.7363636363636363]\n",
      "80/80 [==============================] - 102s 1s/step - loss: 1.2038 - acc: 0.6348\n",
      "Epoch 14/22\n",
      "80/80 [==============================] - 34s 426ms/step - loss: 1.2180 - acc: 0.6398\n",
      "Epoch 15/22\n",
      "80/80 [==============================] - 34s 429ms/step - loss: 1.1205 - acc: 0.6656\n",
      "Epoch 16/22\n",
      "79/80 [============================>.] - ETA: 0s - loss: 1.0805 - acc: 0.6748\n",
      " [0.8818646085162002, 0.7432400932400932]\n",
      "80/80 [==============================] - 102s 1s/step - loss: 1.0852 - acc: 0.6734\n",
      "Epoch 17/22\n",
      "80/80 [==============================] - 34s 426ms/step - loss: 1.0958 - acc: 0.6688\n",
      "Epoch 18/22\n",
      "80/80 [==============================] - 34s 426ms/step - loss: 1.0758 - acc: 0.6762\n",
      "Epoch 19/22\n",
      "79/80 [============================>.] - ETA: 0s - loss: 1.0900 - acc: 0.6816\n",
      " [0.84273720073594, 0.7534965034965035]\n",
      "80/80 [==============================] - 103s 1s/step - loss: 1.0927 - acc: 0.6805\n",
      "Epoch 20/22\n",
      "80/80 [==============================] - 34s 425ms/step - loss: 0.9717 - acc: 0.7035\n",
      "Epoch 21/22\n",
      "80/80 [==============================] - 34s 425ms/step - loss: 0.9546 - acc: 0.7207\n",
      "Epoch 22/22\n",
      "79/80 [============================>.] - ETA: 0s - loss: 1.0492 - acc: 0.6804\n",
      " [0.8339888707583495, 0.76002331002331]\n",
      "80/80 [==============================] - 102s 1s/step - loss: 1.0506 - acc: 0.6809\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f7a14f26ef0>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit_generator(\n",
    "    Train, \n",
    "    steps_per_epoch=80, \n",
    "    epochs=22, \n",
    "    verbose=1, \n",
    "    workers=4,\n",
    "    use_multiprocessing=True,\n",
    "    max_queue_size=20,\n",
    "    initial_epoch=0,\n",
    "    callbacks=[SaveModelandEval_finetune()]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract Xception bottleneck features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# INPUT_SIZE = 299\n",
    "# POOLING = 'avg'\n",
    "# x_train = np.zeros((len(labels), INPUT_SIZE, INPUT_SIZE, 3), dtype='float32')\n",
    "# for i, img_id in tqdm(enumerate(labels['id'])):\n",
    "#     img = read_img(img_id, 'train', (INPUT_SIZE, INPUT_SIZE))\n",
    "#     x = xception.preprocess_input(np.expand_dims(img.copy(), axis=0))\n",
    "#     x_train[i] = x\n",
    "# print('Train Images shape: {} size: {:,}'.format(x_train.shape, x_train.size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Xtr_torch = torch . from_numpy (Xtr)\n",
    "# Xv_torch = torch . from_numpy (Xv)\n",
    "# print(Xv_torch.type)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Xtr = x_train[train_idx]\n",
    "# Xv = x_train[valid_idx]\n",
    "# Xtr_torch = torch . from_numpy (Xtr)\n",
    "# Xv_torch = torch . from_numpy (Xv)\n",
    "# print((Xtr.shape, Xv.shape, ytr.shape, yv.shape))\n",
    "# Xtr_torch=Xtr_torch.cuda()\n",
    "# Xv_torch=Xv_torch.cuda()\n",
    "# xception_bottleneck = xception.Xception(weights='imagenet', include_top=False, pooling=POOLING)\n",
    "# train_x_bf = xception_bottleneck.predict(Xtr, batch_size=32, verbose=1)\n",
    "# valid_x_bf = xception_bottleneck.predict(Xv, batch_size=32, verbose=1)\n",
    "# print('Xception train bottleneck features shape: {} size: {:,}'.format(train_x_bf.shape, train_x_bf.size))\n",
    "# print('Xception valid bottleneck features shape: {} size: {:,}'.format(valid_x_bf.shape, valid_x_bf.size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# xception_bottleneck = xception.Xception(weights='imagenet', include_top=False, pooling=POOLING)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Xtr_torch=torch . from_numpy (Xtr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_x_bf = xception_bottleneck.predict(Xtr_torch, batch_size=32, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# xception_bottleneck = xception.Xception(weights='imagenet', include_top=False, pooling=POOLING)\n",
    "# train_x_bf = xception_bottleneck.predict(Xtr, batch_size=32, verbose=1)\n",
    "# valid_x_bf = xception_bottleneck.predict(Xv, batch_size=32, verbose=1)\n",
    "# print('Xception train bottleneck features shape: {} size: {:,}'.format(train_x_bf.shape, train_x_bf.size))\n",
    "# print('Xception valid bottleneck features shape: {} size: {:,}'.format(valid_x_bf.shape, valid_x_bf.size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Xtr_torch=Xtr_torch.cuda()\n",
    "# Xv_torch=Xv_torch.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(Xtr_torch.type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a=torch.randn(3,5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
